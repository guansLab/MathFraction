{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95297869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\pahad\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\pahad\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568f57b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\pahad\\anaconda3\\lib\\site-packages (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac91cab-7ee9-495d-b03f-e854965f59a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (3167, 28, 28)\n",
      "Labels shape: (3167, 3)\n",
      "First few images: [[[1.         1.         0.99607843 ... 1.         1.         1.        ]\n",
      "  [0.99607843 0.99215686 0.9882353  ... 1.         1.         1.        ]\n",
      "  [0.99607843 0.99607843 1.         ... 1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.         ... 0.7882353  0.95686275 0.9882353 ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]]\n",
      "\n",
      " [[1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  ...\n",
      "  [1.         1.         1.         ... 0.8156863  0.9411765  0.9843137 ]\n",
      "  [1.         1.         1.         ... 0.99215686 0.9882353  0.9882353 ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]]\n",
      "\n",
      " [[1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]\n",
      "  ...\n",
      "  [0.99215686 0.99215686 0.9882353  ... 0.99215686 0.9764706  1.        ]\n",
      "  [0.99607843 0.99607843 1.         ... 0.99607843 1.         1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]]]\n",
      "First few labels: [[11 92  0]\n",
      " [11 92  1]\n",
      " [11 92 10]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def preprocess_fraction_dataset(folder_path, image_size=(28, 28)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Load the image with PIL\n",
    "        with Image.open(file_path) as img:\n",
    "            img = img.convert('L')  # Convert to grayscale\n",
    "            img = img.resize(image_size)  # Resize image\n",
    "            image = np.array(img)  # Convert to numpy array\n",
    "\n",
    "        # Normalize the image\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "\n",
    "        # Extract label from filename\n",
    "        # Adjust the logic below based on your actual filename format\n",
    "        label_parts = filename.split('.')[0].split('_')\n",
    "        label = [int(part) for part in label_parts if part.isdigit()]\n",
    "\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Usage\n",
    "# Usage\n",
    "folder_path = 'data/fraction'\n",
    "images, labels = preprocess_fraction_dataset(folder_path)\n",
    "\n",
    "# Print the shape of the arrays\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# Optionally, print the first few entries\n",
    "print(\"First few images:\", images[:3])\n",
    "print(\"First few labels:\", labels[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8bc2b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (72159, 28, 28)\n",
      "Labels shape: (72159,)\n",
      "First few images: [[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "First few labels: ['0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def preprocess_dataset(data_folder, image_size=(28, 28)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through each class folder\n",
    "    for class_name in os.listdir(data_folder):\n",
    "        class_folder = os.path.join(data_folder, class_name)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(class_folder):\n",
    "            for filename in os.listdir(class_folder):\n",
    "                file_path = os.path.join(class_folder, filename)\n",
    "\n",
    "                # Load the image with PIL\n",
    "                with Image.open(file_path) as img:\n",
    "                    img = img.convert('L')  # Convert to grayscale\n",
    "                    img = img.resize(image_size)  # Resize image\n",
    "                    image = np.array(img)  # Convert to numpy array\n",
    "\n",
    "                # Normalize the image\n",
    "                image = image.astype(np.float32) / 255.0\n",
    "\n",
    "                images.append(image)\n",
    "                labels.append(class_name)  # Use folder name as class label\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Usage\n",
    "data_folder = 'data/'\n",
    "images, labels = preprocess_dataset(data_folder)\n",
    "\n",
    "# Print the shape of the arrays\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# Optionally, print the first few entries\n",
    "print(\"First few images:\", images[:3])\n",
    "print(\"First few labels:\", labels[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f543c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def preprocess_fraction_dataset(folder_path, image_size=(28, 28)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Load the image with PIL\n",
    "        with Image.open(file_path) as img:\n",
    "            img = img.convert('L')  # Convert to grayscale\n",
    "            img = img.resize(image_size)  # Resize image\n",
    "            image = np.array(img)  # Convert to numpy array\n",
    "\n",
    "        # Normalize the image\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "\n",
    "        # Extract label from filename\n",
    "        label_parts = filename.split('.')[0].split('_')\n",
    "        label = [int(part) for part in label_parts if part.isdigit()]\n",
    "\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39037d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (72159, 28, 28)\n",
      "Labels shape: (72159,)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def preprocess_fraction_dataset(base_folder, image_size=(28, 28)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through each class folder\n",
    "    for class_folder in os.listdir(base_folder):\n",
    "        class_folder_path = os.path.join(base_folder, class_folder)\n",
    "\n",
    "        # Check if it's indeed a directory\n",
    "        if os.path.isdir(class_folder_path):\n",
    "            for filename in os.listdir(class_folder_path):\n",
    "                file_path = os.path.join(class_folder_path, filename)\n",
    "\n",
    "                # Check if it's a file, not a sub-directory\n",
    "                if os.path.isfile(file_path):\n",
    "                    # Load the image with PIL\n",
    "                    with Image.open(file_path) as img:\n",
    "                        img = img.convert('L')  # Convert to grayscale\n",
    "                        img = img.resize(image_size)  # Resize image\n",
    "                        image = np.array(img)  # Convert to numpy array\n",
    "\n",
    "                    # Normalize the image\n",
    "                    image = image.astype(np.float32) / 255.0\n",
    "\n",
    "                    images.append(image)\n",
    "                    labels.append(class_folder)  # Use folder name as class label\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Usage\n",
    "folder_path = 'data/'\n",
    "images, labels = preprocess_fraction_dataset(folder_path)\n",
    "\n",
    "# Print the shape of the arrays to verify\n",
    "print(\"Images shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21d30cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(11, activation='softmax')  # Adjust based on the label structure\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b359e297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1624/1624 [==============================] - 8s 4ms/step - loss: 0.1516 - accuracy: 0.9541 - val_loss: 0.0703 - val_accuracy: 0.9790\n",
      "Epoch 2/10\n",
      "1624/1624 [==============================] - 8s 5ms/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 0.0449 - val_accuracy: 0.9875\n",
      "Epoch 3/10\n",
      "1624/1624 [==============================] - 7s 4ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.0431 - val_accuracy: 0.9884\n",
      "Epoch 4/10\n",
      "1624/1624 [==============================] - 7s 4ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.0462 - val_accuracy: 0.9874\n",
      "Epoch 5/10\n",
      "1624/1624 [==============================] - 7s 5ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.0462 - val_accuracy: 0.9856\n",
      "Epoch 6/10\n",
      "1624/1624 [==============================] - 7s 4ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0429 - val_accuracy: 0.9870\n",
      "Epoch 7/10\n",
      "1624/1624 [==============================] - 8s 5ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.0430 - val_accuracy: 0.9886\n",
      "Epoch 8/10\n",
      "1624/1624 [==============================] - 7s 5ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0539 - val_accuracy: 0.9874\n",
      "Epoch 9/10\n",
      "1624/1624 [==============================] - 8s 5ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0545 - val_accuracy: 0.9872\n",
      "Epoch 10/10\n",
      "1624/1624 [==============================] - 7s 5ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0563 - val_accuracy: 0.9896\n"
     ]
    }
   ],
   "source": [
    "# Reshape images for the CNN and train the model\n",
    "images_train = images_train.reshape((-1, 28, 28, 1))  # Reshape for the CNN\n",
    "history = model.fit(images_train, labels_train, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b48883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9896389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels data type: int32\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels data type:\", labels_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98b32bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'labels' contains all your string labels\n",
    "unique_labels = np.unique(labels)\n",
    "label_to_int = {label: i for i, label in enumerate(unique_labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92153e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the full labels array\n",
    "labels_int = np.array([label_to_int[label] for label in labels])\n",
    "\n",
    "# Now split the dataset again with the integer labels\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(\n",
    "    images, labels_int, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92b96533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels data type: int32\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels data type:\", labels_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0071706c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1624/1624 [==============================] - 11s 6ms/step - loss: 0.1527 - accuracy: 0.9530 - val_loss: 0.0501 - val_accuracy: 0.9844\n",
      "Epoch 2/10\n",
      "1624/1624 [==============================] - 10s 6ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.0441 - val_accuracy: 0.9867\n",
      "Epoch 3/10\n",
      "1624/1624 [==============================] - 11s 6ms/step - loss: 0.0317 - accuracy: 0.9901 - val_loss: 0.0373 - val_accuracy: 0.9894\n",
      "Epoch 4/10\n",
      "1624/1624 [==============================] - 11s 7ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0398 - val_accuracy: 0.9880\n",
      "Epoch 5/10\n",
      "1624/1624 [==============================] - 11s 7ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.0448 - val_accuracy: 0.9891\n",
      "Epoch 6/10\n",
      "1624/1624 [==============================] - 11s 7ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0462 - val_accuracy: 0.9870\n",
      "Epoch 7/10\n",
      "1624/1624 [==============================] - 10s 6ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0402 - val_accuracy: 0.9894\n",
      "Epoch 8/10\n",
      "1624/1624 [==============================] - 10s 6ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0384 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "1624/1624 [==============================] - 10s 6ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0435 - val_accuracy: 0.9889\n",
      "Epoch 10/10\n",
      "1624/1624 [==============================] - 10s 6ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0460 - val_accuracy: 0.9910\n"
     ]
    }
   ],
   "source": [
    "# Reshape images for the CNN\n",
    "images_train_reshaped = images_train.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(images_train_reshaped, labels_train, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d98134f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                102464    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121995 (476.54 KB)\n",
      "Trainable params: 121995 (476.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74b5121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1624/1624 [==============================] - 14s 8ms/step - loss: 0.2485 - accuracy: 0.9241 - val_loss: 0.0657 - val_accuracy: 0.9822\n",
      "Epoch 2/10\n",
      "1624/1624 [==============================] - 15s 9ms/step - loss: 0.0809 - accuracy: 0.9770 - val_loss: 0.0613 - val_accuracy: 0.9808\n",
      "Epoch 3/10\n",
      "1624/1624 [==============================] - 16s 10ms/step - loss: 0.0556 - accuracy: 0.9842 - val_loss: 0.0538 - val_accuracy: 0.9858\n",
      "Epoch 4/10\n",
      "1624/1624 [==============================] - 15s 9ms/step - loss: 0.0436 - accuracy: 0.9874 - val_loss: 0.0581 - val_accuracy: 0.9863\n",
      "Epoch 5/10\n",
      "1624/1624 [==============================] - 15s 9ms/step - loss: 0.0342 - accuracy: 0.9902 - val_loss: 0.0500 - val_accuracy: 0.9889\n",
      "Epoch 6/10\n",
      "1624/1624 [==============================] - 16s 10ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.0595 - val_accuracy: 0.9858\n",
      "Epoch 7/10\n",
      "1624/1624 [==============================] - 17s 10ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.0622 - val_accuracy: 0.9856\n",
      "Epoch 8/10\n",
      "1624/1624 [==============================] - 17s 11ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.0658 - val_accuracy: 0.9874\n",
      "Epoch 9/10\n",
      "1624/1624 [==============================] - 18s 11ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.0550 - val_accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "1624/1624 [==============================] - 18s 11ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.0654 - val_accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def create_advanced_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')  # Adjust number of neurons to match number of classes\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and compile the advanced CNN model\n",
    "advanced_cnn_model = create_advanced_cnn_model()\n",
    "advanced_cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape and train the model\n",
    "images_train_reshaped = images_train.reshape((-1, 28, 28, 1))\n",
    "history_advanced_cnn = advanced_cnn_model.fit(images_train_reshaped, labels_train, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11f8945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.9675720620842572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the Random Forest classifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(images_train_flat, labels_train)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_predictions = rf_model.predict(images_test_flat)\n",
    "rf_accuracy = accuracy_score(labels_test, rf_predictions)\n",
    "print(f\"Random Forest Classifier Accuracy: {rf_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9dc4e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy: 0.9431125277161863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the SVM\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Create and train the SVM model\n",
    "svm_model = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "svm_model.fit(images_train_flat, labels_train)\n",
    "\n",
    "# Evaluate the model\n",
    "svm_predictions = svm_model.predict(images_test_flat)\n",
    "svm_accuracy = accuracy_score(labels_test, svm_predictions)\n",
    "print(f\"SVM Classifier Accuracy: {svm_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8cbf1b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1624/1624 [==============================] - 2s 1ms/step - loss: 0.2530 - accuracy: 0.9260 - val_loss: 0.1385 - val_accuracy: 0.9595\n",
      "Epoch 2/10\n",
      "1624/1624 [==============================] - 2s 1ms/step - loss: 0.1066 - accuracy: 0.9672 - val_loss: 0.1004 - val_accuracy: 0.9709\n",
      "Epoch 3/10\n",
      "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0711 - accuracy: 0.9777 - val_loss: 0.0839 - val_accuracy: 0.9759\n",
      "Epoch 4/10\n",
      "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0529 - accuracy: 0.9835 - val_loss: 0.0753 - val_accuracy: 0.9796\n",
      "Epoch 5/10\n",
      "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 0.0836 - val_accuracy: 0.9759\n",
      "Epoch 6/10\n",
      "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0317 - accuracy: 0.9892 - val_loss: 0.0815 - val_accuracy: 0.9766\n",
      "Epoch 7/10\n",
      "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.0815 - val_accuracy: 0.9803\n",
      "Epoch 8/10\n",
      "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0798 - val_accuracy: 0.9799\n",
      "Epoch 9/10\n",
      "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0952 - val_accuracy: 0.9787\n",
      "Epoch 10/10\n",
      "1624/1624 [==============================] - 2s 1ms/step - loss: 0.0185 - accuracy: 0.9936 - val_loss: 0.0915 - val_accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "def create_simple_nn_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28, 1)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')  # Adjust the number of output neurons to the number of classes\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and compile the simple NN model\n",
    "simple_nn_model = create_simple_nn_model()\n",
    "simple_nn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape and train the model\n",
    "images_train_reshaped = images_train.reshape((-1, 28, 28, 1))\n",
    "history_simple_nn = simple_nn_model.fit(images_train_reshaped, labels_train, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7abdaa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Accuracy: 0.9739467849223947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the KNN classifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Create and train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(images_train_flat, labels_train)\n",
    "\n",
    "# Evaluate the model\n",
    "knn_predictions = knn_model.predict(images_test_flat)\n",
    "knn_accuracy = accuracy_score(labels_test, knn_predictions)\n",
    "print(f\"KNN Classifier Accuracy: {knn_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the Gradient Boosting classifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Create and train the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(images_train_flat, labels_train)\n",
    "\n",
    "# Evaluate the model\n",
    "gb_predictions = gb_model.predict(images_test_flat)\n",
    "gb_accuracy = accuracy_score(labels_test, gb_predictions)\n",
    "print(f\"Gradient Boosting Classifier Accuracy: {gb_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0220bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 0.8600332594235033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the Decision Tree classifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Create and train the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(images_train_flat, labels_train)\n",
    "\n",
    "# Evaluate the model\n",
    "dt_predictions = dt_model.predict(images_test_flat)\n",
    "dt_accuracy = accuracy_score(labels_test, dt_predictions)\n",
    "print(f\"Decision Tree Classifier Accuracy: {dt_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b05bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier Accuracy: 0.9292544345898004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for Logistic Regression\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "# Note: For multiclass, Logistic Regression in sklearn uses a one-vs-rest scheme by default\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(images_train_flat, labels_train)\n",
    "\n",
    "# Evaluate the model\n",
    "lr_predictions = lr_model.predict(images_test_flat)\n",
    "lr_accuracy = accuracy_score(labels_test, lr_predictions)\n",
    "print(f\"Logistic Regression Classifier Accuracy: {lr_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "731c38af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}: Accuracy = 0.8596868070953437\n",
      "Decision Tree with {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}: Accuracy = 0.8430570953436807\n",
      "Decision Tree with {'criterion': 'entropy', 'max_depth': 50, 'splitter': 'best'}: Accuracy = 0.8763858093126385\n",
      "Decision Tree with {'criterion': 'gini', 'max_depth': 50, 'splitter': 'best'}: Accuracy = 0.8600332594235033\n",
      "Decision Tree with {'criterion': 'gini', 'max_depth': 10, 'splitter': 'random'}: Accuracy = 0.827120288248337\n",
      "Decision Tree with {'criterion': 'gini', 'max_depth': 50, 'splitter': 'random'}: Accuracy = 0.8612804878048781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the Decision Tree classifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different configurations\n",
    "configurations = [\n",
    "    {\"criterion\": \"entropy\", \"max_depth\": 10, \"splitter\": \"best\"},\n",
    "    {\"criterion\": \"entropy\", \"max_depth\": 10, \"splitter\": \"random\"},\n",
    "    {\"criterion\": \"entropy\", \"max_depth\": 50, \"splitter\": \"best\"},\n",
    "    {\"criterion\": \"gini\", \"max_depth\": 50, \"splitter\": \"best\"},\n",
    "    {\"criterion\": \"gini\", \"max_depth\": 10, \"splitter\": \"random\"},\n",
    "    {\"criterion\": \"gini\", \"max_depth\": 50, \"splitter\": \"random\"}\n",
    "]\n",
    "\n",
    "# Iterate over each configuration, train, and evaluate the model\n",
    "for config in configurations:\n",
    "    dt_model = DecisionTreeClassifier(criterion=config[\"criterion\"],\n",
    "                                      max_depth=config[\"max_depth\"],\n",
    "                                      splitter=config[\"splitter\"],\n",
    "                                      random_state=42)\n",
    "    dt_model.fit(images_train_flat, labels_train)\n",
    "    dt_predictions = dt_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, dt_predictions)\n",
    "    print(f\"Decision Tree with {config}: Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b4ed1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with {'criterion': 'entropy', 'max_depth': 10}: Accuracy = 0.9481014412416852\n",
      "Random Forest with {'criterion': 'entropy', 'max_depth': 50}: Accuracy = 0.9679185144124168\n",
      "Random Forest with {'criterion': 'gini', 'max_depth': 10}: Accuracy = 0.9381929046563193\n",
      "Random Forest with {'criterion': 'gini', 'max_depth': 50}: Accuracy = 0.9675720620842572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the Random Forest classifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different configurations\n",
    "configurations = [\n",
    "    {\"criterion\": \"entropy\", \"max_depth\": 10},\n",
    "    {\"criterion\": \"entropy\", \"max_depth\": 50},\n",
    "    {\"criterion\": \"gini\", \"max_depth\": 10},\n",
    "    {\"criterion\": \"gini\", \"max_depth\": 50}\n",
    "]\n",
    "\n",
    "# Iterate over each configuration, train, and evaluate the model\n",
    "for config in configurations:\n",
    "    rf_model = RandomForestClassifier(n_estimators=100,\n",
    "                                      criterion=config[\"criterion\"],\n",
    "                                      max_depth=config[\"max_depth\"],\n",
    "                                      random_state=42)\n",
    "    rf_model.fit(images_train_flat, labels_train)\n",
    "    rf_predictions = rf_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, rf_predictions)\n",
    "    print(f\"Random Forest with {config}: Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90fea2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with C=0.01 and penalty=l2: Accuracy = 0.9222560975609756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with C=0.1 and penalty=l2: Accuracy = 0.9305016629711752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with C=1 and penalty=l2: Accuracy = 0.9293237250554324\n",
      "Logistic Regression with C=10 and penalty=l2: Accuracy = 0.9285615299334812\n",
      "Logistic Regression with C=0.01 and penalty=l1: Accuracy = 0.8937777161862528\n",
      "Logistic Regression with C=0.1 and penalty=l1: Accuracy = 0.9247505543237251\n",
      "Logistic Regression with C=1 and penalty=l1: Accuracy = 0.9299473392461197\n",
      "Logistic Regression with C=10 and penalty=l1: Accuracy = 0.9284922394678492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with C=1 and penalty=none: Accuracy = 0.9285615299334812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Flatten the images for Logistic Regression\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different configurations\n",
    "configurations = [\n",
    "    {\"C\": 1, \"penalty\": \"l2\"},\n",
    "    {\"C\": 1, \"penalty\": \"l2\"},\n",
    "    {\"C\": 10, \"penalty\": \"l2\"},\n",
    "    {\"C\": 10, \"penalty\": \"l2\"},\n",
    "    {\"C\": 100, \"penalty\": \"l1\"},\n",
    "    {\"C\": 0.1, \"penalty\": \"l1\"},\n",
    "    {\"C\": 1, \"penalty\": \"l1\"},\n",
    "    {\"C\": 10, \"penalty\": \"l1\"},\n",
    "    {\"C\": 1, \"penalty\": \"none\"}\n",
    "]\n",
    "\n",
    "# Iterate over each configuration, train, and evaluate the model\n",
    "for config in configurations:\n",
    "    lr_model = LogisticRegression(C=config[\"C\"], penalty=config[\"penalty\"], solver='saga', max_iter=1000, random_state=42)\n",
    "    lr_model.fit(images_train_flat, labels_train)\n",
    "    lr_predictions = lr_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, lr_predictions)\n",
    "    print(f\"Logistic Regression with C={config['C']} and penalty={config['penalty']}: Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbd0f7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN with n_neighbors=3 and p=1: Accuracy = 0.9703436807095344\n",
      "KNN with n_neighbors=3 and p=2: Accuracy = 0.9751940133037694\n",
      "KNN with n_neighbors=5 and p=1: Accuracy = 0.9684035476718403\n",
      "KNN with n_neighbors=5 and p=2: Accuracy = 0.9737389135254989\n",
      "KNN with n_neighbors=7 and p=1: Accuracy = 0.966809866962306\n",
      "KNN with n_neighbors=7 and p=2: Accuracy = 0.9721452328159645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for KNN\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different settings for neighbors and p\n",
    "settings = [\n",
    "    {\"n_neighbors\": 3, \"p\": 1},\n",
    "    {\"n_neighbors\": 3, \"p\": 2},\n",
    "    {\"n_neighbors\": 5, \"p\": 1},\n",
    "    {\"n_neighbors\": 5, \"p\": 2},\n",
    "    {\"n_neighbors\": 7, \"p\": 1},\n",
    "    {\"n_neighbors\": 7, \"p\": 2}\n",
    "]\n",
    "\n",
    "# Iterate over each setting, train, and evaluate the model\n",
    "for setting in settings:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=setting[\"n_neighbors\"], weights='distance', p=setting[\"p\"])\n",
    "    knn_model.fit(images_train_flat, labels_train)\n",
    "    knn_predictions = knn_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, knn_predictions)\n",
    "    print(f\"KNN with n_neighbors={setting['n_neighbors']} and p={setting['p']}: Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c240c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with C=0.1, kernel=linear, gamma=scale: Accuracy = 0.9465770509977827\n",
      "SVM with C=1, kernel=linear, gamma=scale: Accuracy = 0.9431125277161863\n",
      "SVM with C=0.1, kernel=rbf, gamma=scale: Accuracy = 0.9583564301552107\n",
      "SVM with C=1, kernel=rbf, gamma=scale: Accuracy = 0.9786585365853658\n",
      "SVM with C=0.1, kernel=rbf, gamma=auto: Accuracy = 0.9156735033259423\n",
      "SVM with C=1, kernel=rbf, gamma=auto: Accuracy = 0.9441518847006651\n",
      "SVM with C=0.1, kernel=poly, gamma=scale: Accuracy = 0.948170731707317\n",
      "SVM with C=1, kernel=poly, gamma=scale: Accuracy = 0.9771341463414634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the SVM classifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different configurations\n",
    "configurations = [\n",
    "    {\"C\": 0.1, \"kernel\": \"linear\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 1, \"kernel\": \"linear\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 0.1, \"kernel\": \"rbf\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 1, \"kernel\": \"rbf\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 0.1, \"kernel\": \"rbf\", \"gamma\": \"auto\"},\n",
    "    {\"C\": 1, \"kernel\": \"rbf\", \"gamma\": \"auto\"},\n",
    "    {\"C\": 0.1, \"kernel\": \"poly\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 1, \"kernel\": \"poly\", \"gamma\": \"scale\"}\n",
    "]\n",
    "\n",
    "# Iterate over each configuration, train, and evaluate the model\n",
    "for config in configurations:\n",
    "    svm_model = SVC(C=config[\"C\"], kernel=config[\"kernel\"], gamma=config[\"gamma\"], random_state=42)\n",
    "    svm_model.fit(images_train_flat, labels_train)\n",
    "    svm_predictions = svm_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, svm_predictions)\n",
    "    print(f\"SVM with C={config['C']}, kernel={config['kernel']}, gamma={config['gamma']}: Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a42bdbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC with C=10, kernel=linear, gamma=scale: Accuracy = 0.9311945676274944\n",
      "SVC with C=1, kernel=linear, gamma=scale: Accuracy = 0.9431125277161863\n",
      "SVC with C=10, kernel=rbf, gamma=scale: Accuracy = 0.9853104212860311\n",
      "SVC with C=1, kernel=rbf, gamma=scale: Accuracy = 0.9786585365853658\n",
      "SVC with C=10, kernel=rbf, gamma=auto: Accuracy = 0.9636917960088692\n",
      "SVC with C=1, kernel=rbf, gamma=auto: Accuracy = 0.9441518847006651\n",
      "SVC with C=10, kernel=poly, gamma=scale: Accuracy = 0.9808065410199557\n",
      "SVC with C=1, kernel=poly, gamma=scale: Accuracy = 0.9771341463414634\n",
      "SVC with C=10, kernel=sigmoid, gamma=scale: Accuracy = 0.6492516629711752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the SVM classifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different configurations\n",
    "configurations = [\n",
    "    {\"C\": 10, \"kernel\": \"linear\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 1, \"kernel\": \"linear\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 10, \"kernel\": \"rbf\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 1, \"kernel\": \"rbf\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 10, \"kernel\": \"rbf\", \"gamma\": \"auto\"},\n",
    "    {\"C\": 1, \"kernel\": \"rbf\", \"gamma\": \"auto\"},\n",
    "    {\"C\": 10, \"kernel\": \"poly\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 1, \"kernel\": \"poly\", \"gamma\": \"scale\"},\n",
    "    {\"C\": 10, \"kernel\": \"sigmoid\", \"gamma\": \"scale\"}\n",
    "]\n",
    "\n",
    "# Iterate over each configuration, train, and evaluate the model\n",
    "for config in configurations:\n",
    "    svc_model = SVC(C=config[\"C\"], kernel=config[\"kernel\"], gamma=config[\"gamma\"], random_state=42)\n",
    "    svc_model.fit(images_train_flat, labels_train)\n",
    "    svc_predictions = svc_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, svc_predictions)\n",
    "    print(f\"SVC with C={config['C']}, kernel={config['kernel']}, gamma={config['gamma']}: Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7da75da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy: 0.6411446784922394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the Gaussian Naive Bayes classifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define the Gaussian Naive Bayes classifier with equal priors for 11 classes\n",
    "equal_prior = 1 / 11\n",
    "gnb_model = GaussianNB(priors=[equal_prior] * 11)\n",
    "\n",
    "# Train the model\n",
    "gnb_model.fit(images_train_flat, labels_train)\n",
    "\n",
    "# Evaluate the model\n",
    "gnb_predictions = gnb_model.predict(images_test_flat)\n",
    "accuracy = accuracy_score(labels_test, gnb_predictions)\n",
    "print(f\"Gaussian Naive Bayes Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "688af397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron with penalty='l1': Accuracy = 0.850609756097561\n",
      "Perceptron with penalty='l2': Accuracy = 0.8376524390243902\n",
      "Perceptron with penalty='elasticnet': Accuracy = 0.836890243902439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the Perceptron classifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different penalty settings\n",
    "penalties = ['l1', 'l2', 'elasticnet']\n",
    "\n",
    "# Iterate over each penalty setting, train, and evaluate the model\n",
    "for penalty in penalties:\n",
    "    perceptron_model = Perceptron(penalty=penalty, random_state=42)\n",
    "    perceptron_model.fit(images_train_flat, labels_train)\n",
    "    perceptron_predictions = perceptron_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, perceptron_predictions)\n",
    "    print(f\"Perceptron with penalty='{penalty}': Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5d14aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier with criterion=gini, max_depth=10: Accuracy = 0.9307095343680709\n",
      "ExtraTreesClassifier with criterion=gini, max_depth=50: Accuracy = 0.9701358093126385\n",
      "ExtraTreesClassifier with criterion=entropy, max_depth=10: Accuracy = 0.9350748337028825\n",
      "ExtraTreesClassifier with criterion=entropy, max_depth=50: Accuracy = 0.9703436807095344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the ExtraTreesClassifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different configurations\n",
    "configurations = [\n",
    "    {\"criterion\": \"gini\", \"max_depth\": 10},\n",
    "    {\"criterion\": \"gini\", \"max_depth\": 50},\n",
    "    {\"criterion\": \"entropy\", \"max_depth\": 10},\n",
    "    {\"criterion\": \"entropy\", \"max_depth\": 50}\n",
    "]\n",
    "\n",
    "# Iterate over each configuration, train, and evaluate the model\n",
    "for config in configurations:\n",
    "    etc_model = ExtraTreesClassifier(criterion=config[\"criterion\"], max_depth=config[\"max_depth\"], random_state=42)\n",
    "    etc_model.fit(images_train_flat, labels_train)\n",
    "    etc_predictions = etc_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, etc_predictions)\n",
    "    print(f\"ExtraTreesClassifier with criterion={config['criterion']}, max_depth={config['max_depth']}: Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb1914b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier with C=1: Accuracy = 0.867170177383592\n",
      "PassiveAggressiveClassifier with C=10: Accuracy = 0.867170177383592\n",
      "PassiveAggressiveClassifier with C=100: Accuracy = 0.867170177383592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the PassiveAggressiveClassifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different values for C\n",
    "c_values = [1, 10, 100]\n",
    "\n",
    "# Iterate over each value of C, train, and evaluate the model\n",
    "for c in c_values:\n",
    "    pac_model = PassiveAggressiveClassifier(C=c, random_state=42, max_iter=1000, tol=1e-3)\n",
    "    pac_model.fit(images_train_flat, labels_train)\n",
    "    pac_predictions = pac_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, pac_predictions)\n",
    "    print(f\"PassiveAggressiveClassifier with C={c}: Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19093f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier with loss='hinge' and penalty='l2': Accuracy = 0.9224639689578714\n",
      "SGDClassifier with loss='perceptron' and penalty='l1': Accuracy = 0.8869179600886918\n",
      "SGDClassifier with loss='modified_huber' and penalty='l1': Accuracy = 0.8994595343680709\n",
      "SGDClassifier with loss='modified_huber' and penalty='l2': Accuracy = 0.9171286031042128\n",
      "SGDClassifier with loss='log_loss' and penalty='elasticnet': Accuracy = 0.9219096452328159\n",
      "SGDClassifier with loss='hinge' and penalty='elasticnet': Accuracy = 0.9156042128603105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the SGDClassifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different configurations\n",
    "configurations = [\n",
    "    {\"loss\": \"hinge\", \"penalty\": \"l2\"},\n",
    "    {\"loss\": \"perceptron\", \"penalty\": \"l1\"},\n",
    "    {\"loss\": \"modified_huber\", \"penalty\": \"l1\"},\n",
    "    {\"loss\": \"modified_huber\", \"penalty\": \"l2\"},\n",
    "    {\"loss\": \"log_loss\", \"penalty\": \"elasticnet\"},\n",
    "    {\"loss\": \"hinge\", \"penalty\": \"elasticnet\"}\n",
    "]\n",
    "\n",
    "# Iterate over each configuration, train, and evaluate the model\n",
    "for config in configurations:\n",
    "    sgd_model = SGDClassifier(loss=config[\"loss\"], penalty=config[\"penalty\"], random_state=42, max_iter=1000, tol=1e-3)\n",
    "    sgd_model.fit(images_train_flat, labels_train)\n",
    "    sgd_predictions = sgd_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, sgd_predictions)\n",
    "    print(f\"SGDClassifier with loss='{config['loss']}' and penalty='{config['penalty']}': Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d178308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier with weights='uniform', n_neighbors=5, p=1: Accuracy = 0.9672949002217295\n",
      "KNeighborsClassifier with weights='uniform', n_neighbors=9, p=2: Accuracy = 0.9702050997782705\n",
      "KNeighborsClassifier with weights='distance', n_neighbors=5, p=1: Accuracy = 0.9684035476718403\n",
      "KNeighborsClassifier with weights='distance', n_neighbors=9, p=2: Accuracy = 0.9711751662971175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the images for the KNeighborsClassifier\n",
    "images_train_flat = images_train.reshape((images_train.shape[0], -1))\n",
    "images_test_flat = images_test.reshape((images_test.shape[0], -1))\n",
    "\n",
    "# Define different configurations\n",
    "configurations = [\n",
    "    {\"weights\": \"uniform\", \"n_neighbors\": 5, \"p\": 1},\n",
    "    {\"weights\": \"uniform\", \"n_neighbors\": 9, \"p\": 2},\n",
    "    {\"weights\": \"distance\", \"n_neighbors\": 5, \"p\": 1},\n",
    "    {\"weights\": \"distance\", \"n_neighbors\": 9, \"p\": 2}\n",
    "    # Add more configurations as needed\n",
    "]\n",
    "\n",
    "# Iterate over each configuration, train, and evaluate the model\n",
    "for config in configurations:\n",
    "    knn_model = KNeighborsClassifier(weights=config[\"weights\"], n_neighbors=config[\"n_neighbors\"], p=config[\"p\"])\n",
    "    knn_model.fit(images_train_flat, labels_train)\n",
    "    knn_predictions = knn_model.predict(images_test_flat)\n",
    "    accuracy = accuracy_score(labels_test, knn_predictions)\n",
    "    print(f\"KNeighborsClassifier with weights='{config['weights']}', n_neighbors={config['n_neighbors']}, p={config['p']}: Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ac76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425a6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaca007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273832e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71fc05be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m images_train_reshaped \u001b[38;5;241m=\u001b[39m images_train\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(images_train_reshaped, labels_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Reshape images for the CNN\n",
    "images_train_reshaped = images_train.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(images_train_reshaped, labels_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d95f7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(11, activation='softmax')  # Adjust based on the label structure\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "391a4e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\pahad\\AppData\\Local\\Temp\\ipykernel_19216\\1893078304.py\", line 3, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1155, in train_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1249, in compute_metrics\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 620, in update_state\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\metrics_utils.py\", line 77, in decorated\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 140, in update_state_fn\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_1407]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Reshape images for the CNN and train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m images_train \u001b[38;5;241m=\u001b[39m images_train\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Reshape for the CNN\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(images_train, labels_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\pahad\\AppData\\Local\\Temp\\ipykernel_19216\\1893078304.py\", line 3, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1155, in train_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1249, in compute_metrics\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 620, in update_state\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\metrics_utils.py\", line 77, in decorated\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 140, in update_state_fn\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_1407]"
     ]
    }
   ],
   "source": [
    "# Reshape images for the CNN and train the model\n",
    "images_train = images_train.reshape((-1, 28, 28, 1))  # Reshape for the CNN\n",
    "history = model.fit(images_train, labels_train, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3bc64b",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\pahad\\AppData\\Local\\Temp\\ipykernel_19216\\4107886941.py\", line 3, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2296, in evaluate\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 4108, in run_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2066, in test_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2049, in step_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2037, in run_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1920, in test_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1249, in compute_metrics\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 620, in update_state\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\metrics_utils.py\", line 77, in decorated\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 140, in update_state_fn\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_test_function_1590]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Reshape images for the CNN and evaluate the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m images_test \u001b[38;5;241m=\u001b[39m images_test\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Reshape for the CNN\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(images_test, labels_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_acc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\pahad\\AppData\\Local\\Temp\\ipykernel_19216\\4107886941.py\", line 3, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2296, in evaluate\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 4108, in run_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2066, in test_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2049, in step_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2037, in run_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1920, in test_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1249, in compute_metrics\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 620, in update_state\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\metrics_utils.py\", line 77, in decorated\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 140, in update_state_fn\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_test_function_1590]"
     ]
    }
   ],
   "source": [
    "# Reshape images for the CNN and evaluate the model\n",
    "images_test = images_test.reshape((-1, 28, 28, 1))  # Reshape for the CNN\n",
    "test_loss, test_acc = model.evaluate(images_test, labels_test)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b75824a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\pahad\\AppData\\Local\\Temp\\ipykernel_19216\\1893078304.py\", line 3, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1155, in train_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1249, in compute_metrics\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 620, in update_state\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\metrics_utils.py\", line 77, in decorated\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 140, in update_state_fn\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_1407]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(images_train, labels_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\pahad\\AppData\\Local\\Temp\\ipykernel_19216\\1893078304.py\", line 3, in <module>\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1155, in train_step\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1249, in compute_metrics\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 620, in update_state\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\metrics_utils.py\", line 77, in decorated\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 140, in update_state_fn\n\n  File \"C:\\Users\\pahad\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_1407]"
     ]
    }
   ],
   "source": [
    "model.fit(images_train, labels_train, epochs=5, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32d046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
